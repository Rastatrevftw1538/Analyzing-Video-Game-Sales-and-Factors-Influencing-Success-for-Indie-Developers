{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import Secrets\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import threading\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Data from VGChartz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_games = []\n",
    "def search_for_sales(page_number):\n",
    "    sales_url= \"https://www.vgchartz.com/games/games.php?page=\"+str(page_number)+\"&results=200&order=TotalSales&ownership=Both&direction=DESC&showtotalsales=1&shownasales=0&showpalsales=0&showjapansales=0&showothersales=0&showpublisher=1&showdeveloper=0&showreleasedate=1&showlastupdate=0&showvgchartzscore=0&showcriticscore=0&showuserscore=0&showshipped=1\"\n",
    "    response_sales_data= requests.get(sales_url)\n",
    "    # Parse the HTML content with Beautiful Soup\n",
    "    soup = BeautifulSoup(response_sales_data.content, 'html.parser')\n",
    "    games = soup.find_all('td')\n",
    "    game_names = [element.find('a').get_text() for element in games if element.find('a') and element.get_text(strip=True)]\n",
    "    total_shipped_elements = [element.get_text() for element in games if element.get_text().endswith('m')]\n",
    "    game_index = 0\n",
    "    for game_name in game_names:\n",
    "        game_name = game_name.strip()\n",
    "        if game_name != \"Add new game\":\n",
    "            if game_index < len(total_shipped_elements):\n",
    "                game_dict = {\n",
    "                    \"name\": re.sub(r'\\([^)]*\\)', '', game_name.strip().lower()),\n",
    "                    \"total_shipped\": float(total_shipped_elements[game_index].replace(\"m\", \"\"))\n",
    "                    }\n",
    "                if game_dict[\"name\"].strip().lower() != list_of_games:\n",
    "                    list_of_games.append(game_dict)\n",
    "                game_index+=1\n",
    "threads = []\n",
    "num_of_pages = int(63076/200)\n",
    "for page_number in range(1,num_of_pages+1):\n",
    "    game_thread = threading.Thread(target=search_for_sales,args=(page_number,))\n",
    "    game_thread.start()\n",
    "    threads.append(game_thread)\n",
    "    # pause for web scraping limits to not give read limit errors\n",
    "    time.sleep(2)\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "dataframe = pd.DataFrame(list_of_games, columns=[\"name\", \"total_shipped\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Data from IGDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_url = 'https://id.twitch.tv/oauth2/token?client_id=gq83s6s46z91nf6hf354n9eyqk0ev5&client_secret='+Secrets.Secret_variables.client_secret+'&grant_type=client_credentials'\n",
    "game_criteria_url = 'https://api.igdb.com/v4/games'\n",
    "response = requests.post(auth_url)\n",
    "auth_token = response.json()\n",
    "json_data = []\n",
    "async def fetch_data(session, url, payload, headers):\n",
    "    async with session.post(url, data=payload, headers=headers) as response:\n",
    "        return await response.json()\n",
    "    \n",
    "\n",
    "async def main():\n",
    "    global auth_token\n",
    "    auth_url = 'https://id.twitch.tv/oauth2/token?client_id=gq83s6s46z91nf6hf354n9eyqk0ev5&client_secret='+Secrets.Secret_variables.client_secret+'&grant_type=client_credentials'\n",
    "    game_criteria_url = 'https://api.igdb.com/v4/games'\n",
    "    headers = {'Client-ID': Secrets.Secret_variables.client_id, 'Authorization': \"Bearer \"+auth_token[\"access_token\"]}\n",
    "    tasks = []\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Fetch auth token\n",
    "        async with session.post(auth_url) as response:\n",
    "            auth_token = (await response.json())[\"access_token\"]\n",
    "            headers['Authorization'] = f'Bearer {auth_token}'\n",
    "\n",
    "        for game_name in dataframe[\"name\"]:\n",
    "            payload = 'search \\\"'+ game_name +'\\\"; fields name,alternative_names,age_ratings.rating,game_engines.name, platforms.name, game_modes.name, genres.name,themes.name; exclude alternative_names; where release_dates.y > 2000 & age_ratings.category = 1 & age_ratings.rating != null & game_engines.name != null & platforms.name != null & game_modes.name != null & genres.name != null & themes.name != null;'\n",
    "            task = asyncio.ensure_future(fetch_data(session, game_criteria_url, payload, headers))\n",
    "            tasks.append(task)\n",
    "            # pause for web scraping limits to not give read limit errors\n",
    "            await asyncio.sleep(0.25)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # Process responses here\n",
    "        for response in responses:\n",
    "            json_data.append(response)\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_game_data = []\n",
    "rating_mapping = {\n",
    "    6: \"RP\",\n",
    "    7: \"EC\",\n",
    "    8: \"E\",\n",
    "    9: \"E10\",\n",
    "    10: \"T\",\n",
    "    11: \"M\",\n",
    "    12: \"AO\"\n",
    "}\n",
    "\n",
    "for game_entry in json_data:\n",
    "    if len(game_entry) > 0:\n",
    "        if \"title\" not in game_entry[0].keys():\n",
    "            game_entry = game_entry[0]\n",
    "            game_dict = {\n",
    "                \"name\": game_entry[\"name\"].strip().lower(),\n",
    "                \"genres\": [genre[\"name\"].strip().lower() for genre in game_entry.get(\"genres\", [])],\n",
    "                \"themes\": [theme[\"name\"].strip().lower() for theme in game_entry.get(\"themes\", [])],\n",
    "                \"game_engines\": str(game_entry[\"game_engines\"][0][\"name\"]).strip().lower() if \"game_engines\" in game_entry else \"Unknown\",\n",
    "                \"age_ratings\": \"\".join([\n",
    "                    rating_mapping[age_rating[\"rating\"]].strip().lower()\n",
    "                    for age_rating in game_entry.get(\"age_ratings\", [])\n",
    "                    if age_rating[\"rating\"] in rating_mapping \n",
    "                ]),\n",
    "            }\n",
    "            new_game_data.append(game_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store into Dataframe and write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframe = dataframe\n",
    "new_dataframe = pd.DataFrame(new_game_data, columns=[\"name\", \"genres\", \"themes\", \"game_engines\", \"age_ratings\"])\n",
    "dataframe = pd.merge(old_dataframe,new_dataframe,on=\"name\", how=\"left\")\n",
    "dataframe = dataframe.drop_duplicates(subset=[\"name\"])\n",
    "dataframe = dataframe.dropna()\n",
    "print(dataframe)\n",
    "dataframe.to_csv('videogame_data.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
